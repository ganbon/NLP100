{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ce08f0",
   "metadata": {},
   "source": [
    "# 準備運動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c641897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6c08d",
   "metadata": {},
   "source": [
    "## 00. パタトクカシーー\n",
    "2つの文字列「パトカー」と「タクシー」の文字を先頭から交互に連結し、文字列「パタトクカシーー」を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726c4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "word1 = \"パトカー\"\n",
    "word2 = \"タクシー\"\n",
    "target_string = \"\"\n",
    "for w1,w2 in zip(word1, word2):\n",
    "    target_string += w1 + w2\n",
    "print(target_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ae1d8",
   "metadata": {},
   "source": [
    "## 01. タクシー\n",
    "文字列「パタトクカシーー」の2, 4, 6, 8文字目を取り出し、それらを連結した文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11a04ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシー\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join([target for t, target in enumerate(target_string) if t % 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3af54",
   "metadata": {},
   "source": [
    "## 02. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3738a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "reverse_string = \"\".join(reversed(\"stressed\"))\n",
    "print(reverse_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a854bda",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し、各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322a43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Now', 3],\n",
       " ['I', 1],\n",
       " ['need', 4],\n",
       " ['a', 1],\n",
       " ['drink,', 6],\n",
       " ['alcoholic', 9],\n",
       " ['of', 2],\n",
       " ['course,', 7],\n",
       " ['after', 5],\n",
       " ['the', 3],\n",
       " ['heavy', 5],\n",
       " ['lectures', 8],\n",
       " ['involving', 9],\n",
       " ['quantum', 7],\n",
       " ['mechanics.', 10]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "word_list = target_string.split()\n",
    "word_length_count_dict = [[word, len(word)] for word in word_list]\n",
    "word_length_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40291e63",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し、1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字、それ以外の単語は先頭の2文字を取り出し、取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b639e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hi': 0,\n",
       " 'He': 1,\n",
       " 'L': 2,\n",
       " 'Be': 3,\n",
       " 'Bo': 4,\n",
       " 'Co': 5,\n",
       " 'N': 10,\n",
       " 'O': 7,\n",
       " 'F': 8,\n",
       " 'Mi': 11,\n",
       " 'Al': 12,\n",
       " 'Si': 13,\n",
       " 'Pe': 14,\n",
       " 'Se': 15,\n",
       " 'C': 16,\n",
       " 'A': 17,\n",
       " 'Ki': 18,\n",
       " 'Ca': 19}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "word_list = target_string.split()\n",
    "select_index_list = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "char_place_dict = {}\n",
    "for w,word in enumerate(word_list):\n",
    "    if (w - 1) in select_index_list:\n",
    "        char_place_dict[word[0]] = word_list.index(word)\n",
    "    else:\n",
    "        char_place_dict[word[:2]] = word_list.index(word)\n",
    "char_place_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423a4e1",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ。この関数を用い、”I am an NLPer”という文から文字tri-gram、単語bi-gramを得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba135f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I a', ' am', 'am ', 'm a', ' an', 'an ', 'n N', ' NL', 'NLP', 'LPe', 'Per']\n",
      "['Iam', 'aman', 'anNLPer']\n"
     ]
    }
   ],
   "source": [
    "def create_n_gram(string_list,n):\n",
    "    return [\"\".join(string_list[i:i + n]) for i in range(len(string_list)) if len(string_list[i:]) >= n]\n",
    "\n",
    "target_string = \"I am an NLPer\"\n",
    "print(create_n_gram(target_string, n = 3))\n",
    "word_list = target_string.split()\n",
    "print(create_n_gram(word_list, n = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b3c3a",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を、それぞれ, $X$ と $Y$ として求め、\n",
    "$X$ と $Y$の和集合$(X \\cup Y)$、積集合$(X \\cap Y)$、差集合$(X \\setminus Y)$を求めよ。さらに、’se’というbi-gramがXおよびYに含まれるかどうかを調べよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4592a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合: {'ph', 'gr', 'ra', 'is', 'di', 'ap', 'pa', 'ar', 'ag', 'se', 'ad'}\n",
      "積集合: {'ar', 'ra', 'ap', 'pa'}\n",
      "差集合: {'is', 'di', 'se', 'ad'}\n",
      "含まれる\n",
      "含まれない\n"
     ]
    }
   ],
   "source": [
    "string1 = \"paraparaparadise\"\n",
    "string2 = \"paragraph\"\n",
    "bi_string1 = set(create_n_gram(string1,n = 2))\n",
    "bi_string2 = set(create_n_gram(string2,n = 2))\n",
    "print(\"和集合:\", bi_string1 | bi_string2)\n",
    "print(\"積集合:\", bi_string1 & bi_string2)\n",
    "print(\"差集合:\", bi_string1 - bi_string2)\n",
    "search_char = \"se\"\n",
    "if search_char in bi_string1:\n",
    "    print(\"含まれる\")\n",
    "else:\n",
    "    print(\"含まれない\")\n",
    "if search_char in bi_string2:\n",
    "    print(\"含まれる\")\n",
    "else:\n",
    "    print(\"含まれない\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103932b",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ。さらに、x=12, y=”気温”, z=22.4として、実行結果を確認せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e1ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template_string(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "x, y, z = 12, \"気温\", 22.4\n",
    "print(template_string(x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24798d",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を、以下の仕様で変換する関数cipherを実装せよ。\n",
    "\n",
    "- 英小文字ならば (219 - 文字コード) のASCIIコードに対応する文字に置換\n",
    "\n",
    "- その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い、英語のメッセージを暗号化・復号化せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9de7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号文 : I szev z kvm.\n",
      " 復号文 : I have a pen.\n"
     ]
    }
   ],
   "source": [
    "def cipher(string : str):\n",
    "    pattern = re.compile(r\"[a-z]+\")\n",
    "    convert_char = \"\".join(pattern.findall(string))\n",
    "    convert_dict = {}\n",
    "    for char in convert_char:\n",
    "        convert_dict[char] = chr(219 - ord(char))\n",
    "    return string.translate(str.maketrans(convert_dict))\n",
    "\n",
    "test_string = \"I have a pen.\"\n",
    "cipher_text = cipher(test_string)\n",
    "decodeing_text = cipher(cipher_text)\n",
    "print(f\"暗号文 : {cipher_text}\\n 復号文 : {decodeing_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c44a5",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して、各単語の先頭と末尾の文字は残し、それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ。ただし、長さが４以下の単語は並び替えないこととする。適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え、その実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "365953ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cuod’lnt bleveie that I cloud auacltly ueatsnnrdd what I was reidang : the pnmaenheol pwoer of the huamn mind .\n"
     ]
    }
   ],
   "source": [
    "def random_place(strings):\n",
    "    return \" \".join([word[0] + \"\".join(random.sample(word[1:-1],len(word[1:-1]))) + word[-1]\n",
    "            if len(word) > 4 else word for word in strings.split()])\n",
    "\n",
    "test_string = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(random_place(test_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
