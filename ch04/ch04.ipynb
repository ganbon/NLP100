{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cde10c6",
   "metadata": {},
   "source": [
    "# 第4章: 言語解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19bebf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sudachipy\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d7c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "メロスは激怒した。\n",
    "必ず、かの邪智暴虐の王を除かなければならぬと決意した。\n",
    "メロスには政治がわからぬ。\n",
    "メロスは、村の牧人である。\n",
    "笛を吹き、羊と遊んで暮して来た。\n",
    "けれども邪悪に対しては、人一倍に敏感であった。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a62e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = sudachipy.Dictionary() \n",
    "tokenizer = dict.create() \n",
    "nlp = spacy.load('ja_ginza')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b37974",
   "metadata": {},
   "source": [
    "## 30. 動詞\n",
    "文章textに含まれる動詞をすべて表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8190b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "し ('動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般')\n",
      "除か ('動詞', '一般', '*', '*', '五段-カ行', '未然形-一般')\n",
      "なら ('動詞', '非自立可能', '*', '*', '五段-ラ行', '未然形-一般')\n",
      "し ('動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般')\n",
      "わから ('動詞', '一般', '*', '*', '五段-ラ行', '未然形-一般')\n",
      "ある ('動詞', '非自立可能', '*', '*', '五段-ラ行', '終止形-一般')\n",
      "吹き ('動詞', '一般', '*', '*', '五段-カ行', '連用形-一般')\n",
      "遊ん ('動詞', '一般', '*', '*', '五段-バ行', '連用形-撥音便')\n",
      "暮し ('動詞', '一般', '*', '*', '五段-サ行', '連用形-一般')\n",
      "来 ('動詞', '非自立可能', '*', '*', 'カ行変格', '連用形-一般')\n",
      "対し ('動詞', '一般', '*', '*', 'サ行変格', '連用形-一般')\n",
      "あっ ('動詞', '非自立可能', '*', '*', '五段-ラ行', '連用形-促音便')\n"
     ]
    }
   ],
   "source": [
    "morphs = tokenizer.tokenize(text, mode=sudachipy.SplitMode.B)\n",
    "for m in morphs:\n",
    "    if m.part_of_speech()[0] == \"動詞\":\n",
    "        print(m.surface(), m.part_of_speech())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84d3a9",
   "metadata": {},
   "source": [
    "## 31. 動詞の原型\n",
    "文章textに含まれる動詞と、その原型をすべて表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7414c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "する ('動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般')\n",
      "除く ('動詞', '一般', '*', '*', '五段-カ行', '未然形-一般')\n",
      "なる ('動詞', '非自立可能', '*', '*', '五段-ラ行', '未然形-一般')\n",
      "する ('動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般')\n",
      "わかる ('動詞', '一般', '*', '*', '五段-ラ行', '未然形-一般')\n",
      "ある ('動詞', '非自立可能', '*', '*', '五段-ラ行', '終止形-一般')\n",
      "吹く ('動詞', '一般', '*', '*', '五段-カ行', '連用形-一般')\n",
      "遊ぶ ('動詞', '一般', '*', '*', '五段-バ行', '連用形-撥音便')\n",
      "暮す ('動詞', '一般', '*', '*', '五段-サ行', '連用形-一般')\n",
      "来る ('動詞', '非自立可能', '*', '*', 'カ行変格', '連用形-一般')\n",
      "対する ('動詞', '一般', '*', '*', 'サ行変格', '連用形-一般')\n",
      "ある ('動詞', '非自立可能', '*', '*', '五段-ラ行', '連用形-促音便')\n"
     ]
    }
   ],
   "source": [
    "morphs = tokenizer.tokenize(text, mode=sudachipy.SplitMode.B)\n",
    "for m in morphs:\n",
    "    if m.part_of_speech()[0] == \"動詞\":\n",
    "        print(m.dictionary_form(), m.part_of_speech())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cfdbf",
   "metadata": {},
   "source": [
    "## 32. 「AのB」\n",
    "文章textにおいて、2つの名詞が「の」で連結されている名詞句をすべて抽出せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fe88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['暴虐の王', '村の牧人']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphs = tokenizer.tokenize(text, mode=sudachipy.SplitMode.B)\n",
    "noun_chain,results = [],[]\n",
    "for m in morphs:\n",
    "    if m.part_of_speech()[0] == \"名詞\":\n",
    "        if \"の\" in noun_chain:\n",
    "            noun_chain.append(m.surface())\n",
    "            results.append(\"\".join(noun_chain))\n",
    "        noun_chain = [m.surface()]\n",
    "    elif m.surface() == \"の\" and noun_chain != []:\n",
    "        noun_chain.append(m.surface())\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39abd3b",
   "metadata": {},
   "source": [
    "## 33. 係り受け解析\n",
    "文章textに係り受け解析を適用し、係り元と係り先のトークン（形態素や文節などの単位）をタブ区切り形式ですべて抽出せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b136d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  メロス\n",
      "メロス  激怒\n",
      "は  メロス\n",
      "激怒  激怒\n",
      "し  激怒\n",
      "た  激怒\n",
      "。  激怒\n",
      "\n",
      "  \n",
      "\n",
      "必ず  除か\n",
      "、  必ず\n",
      "かの  暴虐\n",
      "邪智  暴虐\n",
      "暴虐  王\n",
      "の  暴虐\n",
      "王  除か\n",
      "を  王\n",
      "除か  決意\n",
      "なけれ  除か\n",
      "ば  なけれ\n",
      "なら  なけれ\n",
      "ぬ  なけれ\n",
      "と  除か\n",
      "決意  決意\n",
      "し  決意\n",
      "た  決意\n",
      "。  決意\n",
      "\n",
      "  メロス\n",
      "メロス  わから\n",
      "に  メロス\n",
      "は  メロス\n",
      "政治  わから\n",
      "が  政治\n",
      "わから  わから\n",
      "ぬ  わから\n",
      "。  わから\n",
      "\n",
      "  メロス\n",
      "メロス  牧人\n",
      "は  メロス\n",
      "、  メロス\n",
      "村  牧人\n",
      "の  村\n",
      "牧人  牧人\n",
      "で  牧人\n",
      "ある  で\n",
      "。  牧人\n",
      "\n",
      "  笛\n",
      "笛  吹き\n",
      "を  笛\n",
      "吹き  暮し\n",
      "、  吹き\n",
      "羊  遊ん\n",
      "と  羊\n",
      "遊ん  暮し\n",
      "で  遊ん\n",
      "暮し  暮し\n",
      "て  暮し\n",
      "来  て\n",
      "た  暮し\n",
      "。  暮し\n",
      "\n",
      "  邪悪\n",
      "けれど  \n",
      "\n",
      "も  \n",
      "\n",
      "邪悪  敏感\n",
      "に  邪悪\n",
      "対し  に\n",
      "ては  に\n",
      "、  邪悪\n",
      "人  倍\n",
      "一  倍\n",
      "倍  敏感\n",
      "に  倍\n",
      "敏感  敏感\n",
      "で  敏感\n",
      "あっ  で\n",
      "た  敏感\n",
      "。  敏感\n",
      "\n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(f\"{token.text}  {token.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f1821",
   "metadata": {},
   "source": [
    "## 34. 主述の関係\n",
    "文章textにおいて、「メロス」が主語であるときの述語を抽出せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89f21c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メロス  激怒\n",
      "メロス  牧人\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if token.text == \"メロス\" and token.dep_ == \"nsubj\":\n",
    "            print(f\"{token.text}  {token.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6846e",
   "metadata": {},
   "source": [
    "## 35. 係り受け木\n",
    "「メロスは激怒した。」の係り受け木を可視化せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24b35edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ja\" id=\"fc9ac3a6a6554d8bb83ceeba2e0c2568-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">メロス</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">は</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">激怒</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">し</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">た。</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fc9ac3a6a6554d8bb83ceeba2e0c2568-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "doc = nlp(\"メロスは激怒した。\")\n",
    "for sent in doc.sents:\n",
    "    svg = displacy.render(sent, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff84045",
   "metadata": {},
   "source": [
    "## 36. 単語の出現頻度\n",
    "問題36から39までは、Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzをコーパスと見なし、統計的な分析を行う。\n",
    "\n",
    "1行に1記事の情報がJSON形式で格納される\n",
    "\n",
    "各行には記事名が”title”キーに、記事本文が”text”キーの辞書オブジェクトに格納され、そのオブジェクトがJSON形式で書き出される\n",
    "\n",
    "ファイル全体はgzipで圧縮される\n",
    "\n",
    "まず、第3章の処理内容を参考に、Wikipedia記事からマークアップを除去し、各記事のテキストを抽出せよ。そして、コーパスにおける単語（形態素）の出現頻度を求め、出現頻度の高い20語とその出現頻度を表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84999b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "text = \"\"\n",
    "emphasis_pattern = re.compile(r'\\'+(.+?)\\'+')\n",
    "internal_link_pattern = re.compile(r'\\[\\[(.+?)\\]\\]')\n",
    "holaizon_pattern = re.compile(r'-+')\n",
    "section_pattern = re.compile(r'={2,6}(.+)={2,6}')\n",
    "br_pattern = re.compile(r'<br />')\n",
    "ref_pattern = re.compile(r'<ref .+ />')\n",
    "ref_pattern2 = re.compile(r'<ref.*>.+</ref>')\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "## クリーニングが甘い状態\n",
    "with open(\"./jawiki-country.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    country_data =  [json.loads(l) for l in f.readlines()]\n",
    "for c,country in enumerate(country_data):\n",
    "    body = country[\"text\"]\n",
    "    body = emphasis_pattern.sub('\\\\1',body)\n",
    "    body = internal_link_pattern.sub('\\\\1',body)\n",
    "    body = section_pattern.sub('\\\\1',body)\n",
    "    body = holaizon_pattern.sub('',body)\n",
    "    body = br_pattern.sub('',body)\n",
    "    body = ref_pattern.sub('',body)\n",
    "    body = ref_pattern2.sub('',body)\n",
    "    country_data[c][\"text\"] = body\n",
    "    text += body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38635c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  152478\n",
      "| 106733\n",
      "の 87540\n",
      "、 77662\n",
      "に 57024\n",
      "。 48647\n",
      "は 47143\n",
      "が 40129\n",
      "{ 39812\n",
      "} 39798\n",
      "= 35086\n",
      "を 34890\n",
      "て 32651\n",
      "た 32218\n",
      "で 31397\n",
      "と 31176\n",
      "し 27282\n",
      "年 25028\n",
      "・ 24536\n",
      "） 17424\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for b in text.split(\"\\n\"):\n",
    "    morphs = tokenizer.tokenize(b, mode=sudachipy.SplitMode.B)\n",
    "    for m in morphs:\n",
    "        if m.surface() in word_dict.keys():\n",
    "            word_dict[m.surface()] += 1\n",
    "        else:\n",
    "            word_dict[m.surface()] = 1\n",
    "            \n",
    "for key,value in sorted(word_dict.items(),key=lambda x:x[1],reverse=True)[:20]:\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdc220",
   "metadata": {},
   "source": [
    "## 37. 名詞の出現頻度\n",
    "コーパスにおける名詞の出現頻度を求め、出現頻度の高い20語とその出現頻度を表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8e71ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年 25028\n",
      "月 9864\n",
      "en 6317\n",
      "% 5164\n",
      "1 4773\n",
      "2 4400\n",
      "リンク 4186\n",
      "こと 4108\n",
      "日本 3785\n",
      "世界 3712\n",
      "仮 3672\n",
      "共和国 3551\n",
      "語 3411\n",
      "大統領 3350\n",
      "of 3316\n",
      "3 3217\n",
      "アメリカ 3206\n",
      "政府 3196\n",
      "thumb 3047\n",
      "ため 2888\n"
     ]
    }
   ],
   "source": [
    "noun_dict = {}\n",
    "for b in text.split(\"\\n\"):\n",
    "    morphs = tokenizer.tokenize(b, mode=sudachipy.SplitMode.B)\n",
    "    for m in morphs:\n",
    "        if m.part_of_speech()[0] == \"名詞\":\n",
    "            if m.surface() in noun_dict.keys():\n",
    "                noun_dict[m.surface()] += 1\n",
    "            else:\n",
    "                noun_dict[m.surface()] = 1\n",
    "            \n",
    "for key,value in sorted(noun_dict.items(),key=lambda x:x[1],reverse=True)[:20]:\n",
    "    print(key,value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d75a0b",
   "metadata": {},
   "source": [
    "## 38. TF・IDF\n",
    "日本に関する記事における名詞のTF・IDFスコアを求め、TF・IDFスコア上位20語とそのTF, IDF, TF・IDFを表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13828d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word,text):\n",
    "    return text.count(word)\n",
    "\n",
    "def idf(word,collections):\n",
    "    count = 0\n",
    "    for collection in collections:\n",
    "        if word in collection:\n",
    "            count += 1\n",
    "    return np.log(1+len(collections)/count)\n",
    "\n",
    "def tf_idf(word,text,collections):\n",
    "    return tf(word,text)*idf(word,collections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
